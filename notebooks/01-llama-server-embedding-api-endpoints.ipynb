{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422dc501-69bf-4105-b800-9f14c596c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff78001-5c11-499c-9bb9-e150fa928ac9",
   "metadata": {},
   "source": [
    "# Embedding API Endpoint\n",
    "\n",
    "This tutorial demonstrates how to generate embedding vectors using LLaMA C++.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e14ac0-87fd-4331-834b-8d191f768d67",
   "metadata": {},
   "source": [
    "## Quick Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7143d5-a9c8-4f80-a0d9-a8b626879136",
   "metadata": {},
   "source": [
    "### Download an embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de48c682-f769-49a5-92cd-f606396a5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "MODEL_URL=https://huggingface.co/nomic-ai/nomic-embed-text-v1.5-GGUF/resolve/main/nomic-embed-text-v1.5.Q4_K_M.gguf\n",
    "curl --location --output ../models/nomic-embed-text-v1.5.Q4_K_M.gguf $MODEL_URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345659f-baf2-4ad9-ae75-3dc61b91bec7",
   "metadata": {},
   "source": [
    "### Start your embedding server\n",
    "\n",
    "To use the `embedding` API endpoint you must start the server using the `--embedding` option (and without using the `--reranking` option). Open a new terminal and run the following command to start a new server with the embeddings endpoint enabled.\n",
    "\n",
    "```bash\n",
    "MODEL=\"./models/nomic-embed-text-v1.5.Q4_K_M.gguf\"\n",
    "llama-server \\\n",
    "    --model $MODEL \\\n",
    "    --host localhost \\\n",
    "    --port 8081 \\\n",
    "    --embedding\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8653bf-7dca-4b7d-87d5-b54c7561509f",
   "metadata": {},
   "source": [
    "## Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac232c5e-095e-481d-a356-16b2ef982e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"http://localhost:8081/health\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0e34e8-52b4-41fc-aa64-3aa149bc1a10",
   "metadata": {},
   "source": [
    "## Basic Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a3bda6-4f35-4ce3-9ed6-972fb8c676f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    url=\"http://localhost:8081/embedding\",\n",
    "    json={\n",
    "        \"content\": \"Why is the sky blue?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8fa15e-3116-4102-9fa8-4bd336a22894",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.loads(response.content)\n",
    "JSON(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6653654-852d-4a98-8478-f64c35588081",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_arr = np.array(json_data[\"embedding\"])\n",
    "embedding_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf83b8-dc14-4e9c-910c-34bcc4ea9df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
