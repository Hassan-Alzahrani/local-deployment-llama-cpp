gguf
llama-cpp-python --config-settings cmake.args="-DLLAMA_CURL=ON;-DGGML_ACCELERATE=OFF;-DGGML_METAL=OFF;-DGGML_LLAMAFILE=OFF;-DGGML_BLAS=ON;-DGGML_BLAS_VENDOR=OpenBLAS"
